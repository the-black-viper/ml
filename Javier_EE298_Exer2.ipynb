{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mod2 NN_basic.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "67tmHqQvkJiv",
        "hI1nsp-aWnhS"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMm/1/fT0TX3SETLXV28JeF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/the-black-viper/ml/blob/main/Javier_EE298_Exer2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSfjLLgEOdPv"
      },
      "source": [
        "# Goal\n",
        "\n",
        "Create a simple 3-layer neural network using purely python and numpy to predict the probabilities of normaly distributed values within $(-2\\sigma, + 2\\sigma)$ using the following architecture:\n",
        "\n",
        "- 1 unit - Input Layer\n",
        "- 64 units - Hidden Layer 1 + Relu Activation function\n",
        "- 64 units - Hidden Layer 2 + Relu Activation function\n",
        "- 1 unit - Output Layer\n",
        "\n",
        "Hyperparameters\n",
        "- Epochs: 20\n",
        "- Batch size: 1\n",
        "- Learning Rate = 0.1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0mfo5QpV8GV"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from math import floor"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia4Xjrbkjy0X"
      },
      "source": [
        "# Define Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUvisBVuP0gx"
      },
      "source": [
        "def get_input():\n",
        "  '''Get user input for the mean and std deviation\n",
        "  Returns:\n",
        "  user_mean(float) - mean\n",
        "  user_std(float) - standard deviation\n",
        "  '''\n",
        "  mean_ = input('Enter mean: ')\n",
        "  std_ = input('Enter standard deviation: ')\n",
        "  user_mean = float(mean_)\n",
        "  user_std = float(std_)\n",
        "  return user_mean, user_std"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LXeh9vSYPqa"
      },
      "source": [
        "def flatten_stack(arr):\n",
        "  '''\n",
        "  Flattens a 2D array and reshapes it into a single column vector\n",
        "  \n",
        "  Parameters:\n",
        "  arr(numpy.array) - array to flatten\n",
        "\n",
        "  Returns:\n",
        "  reshaped_arr(numpy.array) - Single column vector of the input array\n",
        "  '''\n",
        "  flattened_arr = arr.flatten()\n",
        "  # arr_new = np.array([[x] for x in flattened_arr])\n",
        "  reshaped_arr = flattened_arr.reshape((flattened_arr.shape[0],1))\n",
        "  return reshaped_arr"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thadjS9a0bNk"
      },
      "source": [
        "def scale(X):\n",
        "  '''\n",
        "  Normalizes X values for easier processing\n",
        "  \n",
        "  Parameters:\n",
        "  X(numpy.array) - Raw input data to be normalized\n",
        "\n",
        "  Returns:\n",
        "  scaled_x(numpy.array) - Normalized input values\n",
        "  mean_x(float) - mean of raw input data\n",
        "  std_x(float) - standard deviation of raw input data\n",
        "  '''\n",
        "  mean_x = np.mean(X, axis=0)\n",
        "  new = X - mean_x\n",
        "  std_x = np.std(X, axis=0)\n",
        "  scaled_x = new / std_x \n",
        "  return scaled_x, mean_x, std_x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnHHf6yORN3-"
      },
      "source": [
        "def filter(input, output, n=10):\n",
        "  '''\n",
        "  Randomly selects n samples from the first row with a matching\n",
        "  key from the second column.\n",
        "\n",
        "  Parameters:\n",
        "  input(numpy.array) - Input matrix to select samples\n",
        "  output(int/float) - Value to match in the second column\n",
        "  n(int, default = 10) - Number of samples to select\n",
        "\n",
        "  Returns:\n",
        "  new_x(numpy.array) - Row vector with size (n,)\n",
        "  '''\n",
        "  # Select all rows with the second column matching the output\n",
        "  rows_with_output = input[(input[:, 1] == output)]\n",
        "  # Get only the first column (X values)\n",
        "  input_vals = rows_with_output[:,0]\n",
        "  # Randomly pick 10 samples\n",
        "  generator = np.random.default_rng(42)\n",
        "  new_x = generator.choice(input_vals, n)\n",
        "  return new_x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmGCLpsRNsVn"
      },
      "source": [
        "def random_range(lb, ub, n):\n",
        "  '''Function to generate 'n' uniform random numbers in the interval (lb, ub]\n",
        "  Parameters:\n",
        "  lb - lower bound\n",
        "  ub - upper bound\n",
        "  n - number of random numbers to generate\n",
        "\n",
        "  Returns:\n",
        "  random_nums(numpy.array) - array of random numbers\n",
        "  '''\n",
        "  generator = np.random.default_rng(42)\n",
        "  random_nums = generator.uniform(lb, ub, n)\n",
        "  return random_nums"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0SwnXTfTgIC"
      },
      "source": [
        "# Activation Functions\n",
        "\n",
        "Define activation functions ReLu & Sigmoid and their respective derivatives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gi0oZ1bV8u1"
      },
      "source": [
        "'''\n",
        "Parameters:\n",
        "z - Weighted input matrix\n",
        "\n",
        "Returns:\n",
        "a (float) - 'Activated' values\n",
        "'''\n",
        "\n",
        "def relu(z):\n",
        "  a = z * (z > 0)\n",
        "  return a\n",
        "\n",
        "def relu_prime(z):\n",
        "  z[z < 0] = 0\n",
        "  z[z > 0] = 1\n",
        "  return z\n",
        "\n",
        "def sigmoid(z):\n",
        "  a = 1.0 / (1 + np.exp(-z))\n",
        "  return a\n",
        "\n",
        "def sigmoid_prime(z):\n",
        "  a = sigmoid(z) * (1.0-sigmoid(z))\n",
        "  return a "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67tmHqQvkJiv"
      },
      "source": [
        "# Cost Function\n",
        "Define the MSE cost function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VeiG_g6lyNc"
      },
      "source": [
        "def mse(yHat, y):\n",
        "  ''' Returns the mean-squared-error of the predicted\n",
        "  and target values\n",
        "  Parameters:\n",
        "  yHat(np.array) - predicted values\n",
        "  y(np.array) - ground truth\n",
        "\n",
        "  Returns:\n",
        "  c - mean-squared-error\n",
        "  '''\n",
        "  c = np.sum((yHat - y)**2) / y.size\n",
        "  return c"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StQNNmrHag3a"
      },
      "source": [
        "# Creating the Dataset\n",
        "Target dataset is composed of random variables $(x)$ and their respective probability as the output $(y)$\n",
        "\n",
        "A histogram plot is first generated to 'discretize' a normal random distribution. Eventually, inputs $(x)$ will be derived from the bin centers and the probabilities $(y)$ are calculated from the respective frequencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDBZ_u_6Hg8g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "5d26735d-aa71-47fd-c044-55b0eeb33247"
      },
      "source": [
        "np.random.seed(42)\n",
        "# Define mean and std\n",
        "mu, sigma = get_input()\n",
        "num_bins = 100\n",
        "raw_sample_size = 15000\n",
        "raws = np.random.normal(mu, sigma, raw_sample_size).round(4)\n",
        "hist, bin_edges = np.histogram(raws, bins=num_bins)\n",
        "# Half bin width\n",
        "bin_half_val = np.diff(bin_edges)/2\n",
        "# Get the bin centers\n",
        "bin_centers = bin_edges[:-1] + np.diff(bin_edges)/2\n",
        "# Plot the 'discretized' distribution\n",
        "plt.scatter(bin_centers, hist)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter mean: 100\n",
            "Enter standard deviation: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f34fa45da20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg-7-b0zu8vV"
      },
      "source": [
        "## Select values in the range $(-2\\sigma, +2\\sigma)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zgeoM2uu4vJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "9afc6fd6-a4d0-4a8c-c2ea-ba8be92cbdcc"
      },
      "source": [
        "# Define bounds\n",
        "lb = mu - 2*sigma\n",
        "ub = mu + 2*sigma\n",
        "# Select bin_centers inside the range [lb, ub]\n",
        "bins = bin_centers[(bin_centers >= lb) & (bin_centers < ub)]\n",
        "bin_idx = [np.where(bin_centers == bin) for bin in bins]\n",
        "\n",
        "# Flatten index\n",
        "bin_idx = np.array(bin_idx).flatten()\n",
        "# Get frequency values for respective bin centers\n",
        "hist_in_range = hist[bin_idx]\n",
        "\n",
        "# Plot\n",
        "plt.scatter(bins, hist_in_range)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f3502e9cef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-wI4hiscbvF"
      },
      "source": [
        "## Generate dataset from the 'discretized' distribution.\n",
        "\n",
        "To generate the dataset, random numbers are generated for each bin interval. The respective probabilities are calculated and the two sets of data are combined into a single matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhyodR0O3H3P"
      },
      "source": [
        "# Define number of samples for each bin\n",
        "num_data = 1\n",
        "\n",
        "# For each bin generate 10 random numbers in the interval.\n",
        "x_raw = np.array([random_range(x-bin_half_val[0], x+bin_half_val[0], num_data).reshape((num_data, 1)) for x in bins])\n",
        "x_raw = x_raw.reshape(len(bins),1,num_data)\n",
        "\n",
        "# Generate the probabilities.\n",
        "y_raw = np.array([np.full((num_data,1), round(f/raw_sample_size, 4)) for f in hist_in_range])\n",
        "\n",
        "# Flatten the arrays\n",
        "y_f = flatten_stack(y_raw)\n",
        "x_f = flatten_stack(x_raw)\n",
        "\n",
        "# Apply scaling and transformation\n",
        "x_scaled,x_mean, x_std = scale(x_f)\n",
        "scale1 = (x_f[0][0] -np.mean(x_f))/np.std(x_f)\n",
        "\n",
        "# Finally, combine the inputs and outputs into a single 2D Matrix.\n",
        "data_raw = np.hstack((x_scaled, y_f))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKelfJnyjP8A"
      },
      "source": [
        "## Split Dataset\n",
        "The dataset is shuffled to introduce randomness prior splitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL4cT7120nZq"
      },
      "source": [
        "def train_test_split(dataset, train_ratio, N, data_per_sample):\n",
        "  '''\n",
        "  Splits a 2D dataset into training and test sets\n",
        "  Parameters:\n",
        "  dataset(numpy.array) - 2D numpy array to split\n",
        "  train_ratio(np.float) - float value of the training percentage\n",
        "  N(int) - total number of samples\n",
        "  data_per_sample - number of data sets \n",
        "  '''\n",
        "  # Apply shuffling a second time\n",
        "  np.random.shuffle(dataset)\n",
        "\n",
        "  # Define training data ratio\n",
        "  train_index = int(train_ratio*N)\n",
        "\n",
        "  # Round train_index\n",
        "  train_index = data_per_sample * floor(train_index/data_per_sample)\n",
        "  # Get training and test sets\n",
        "  training_set, test_set = dataset[0:train_index], dataset[train_index:]\n",
        "  return training_set, test_set"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rCCz8GDJDOU"
      },
      "source": [
        "# Split dataset to training and test sets\n",
        "train_set, test_set = train_test_split(data_raw, 0.9, data_raw.shape[0], num_data)\n",
        "np.random.shuffle(train_set)\n",
        "np.random.shuffle(test_set)\n",
        "# Training Set\n",
        "x_training = train_set[:,0].reshape(-1,1)\n",
        "y_training = train_set[:,1].reshape(-1,1)\n",
        "# Test Set\n",
        "x_testing = test_set[:,0].reshape(-1,1)\n",
        "y_testing = test_set[:,1].reshape(-1,1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI1nsp-aWnhS"
      },
      "source": [
        "# Network Discussion and Calculations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM5BG-ihX1UN"
      },
      "source": [
        "## Notations\n",
        "\n",
        "- $W$: Weights\n",
        "- $b$: Weights\n",
        "- $z$: Weighted inputs + bias where: $z = Wx + b$\n",
        "- $a$: Activated neurons where the activation function ($\\sigma$) is applied to z,  where: $a = \\sigma(z)$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvvrpMYEZ2Im"
      },
      "source": [
        "## Forward Propagation\n",
        "\n",
        "For each unit in each layer the vector of activated neurons ($a$) must be calculated. In order to calculate $a$, $z$ must first be calculated for each neuron in that particular layer.\n",
        "\n",
        "From the notation previously defined. $z$ is simply defined as:\n",
        "\n",
        "$$Weights * Input + bias$$\n",
        "\n",
        "And looking at the network, for each layer the final output will be $a$. In the case of the first input layer, the input data will serve as the output $a$. Using this logic, then a generalized formula for $z$ is:\n",
        "\n",
        "$$z^l = w^l(a^{l-1}) + b^l$$\n",
        "\n",
        "Where the superscript defines the layer index.\n",
        "\n",
        "In order to translate this into code. Pictorially, each layer has a vector as inputs, and each unit in that layer has a weight connected to the neuron to the next layer. This implies that the weights can be viewed in matrix form, where each row of that matrix identifies the ith neuron and the elements in that row are the weights (connections) to each neuron of the previous layer. This can be done mathematically and is simply the dot product of the weight matrix and the input vector. \n",
        "\n",
        "To calculate $z^l$ the bias vector, $b^l$ is simply added to the resulting vector.\n",
        "\n",
        "This will be computed for each layer until the final layer where:\n",
        "$$a^L = \\sigma(z^L)$$\n",
        "will serve as the predicted output of the model.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpkZjOQGflXb"
      },
      "source": [
        "## Cost/Loss\n",
        "One forward propagation yields the predicted output, and to estimate how good the model is in predicting the output a cost or loss function is used. In this particlar case, the MSE loss function will be used.\n",
        "$$\n",
        "MSE = \\frac{1}{N}\\sum^N_{i=0}(y^p - y)^2\n",
        "$$\n",
        "\n",
        "The cost average is calculated after every pass."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPMjBoqCfpIM"
      },
      "source": [
        "## Backpropagation\n",
        "\n",
        "Essentially for a model to learn the hyper parameters (Weights and biases) must be adjusted until the model has an acceptable 'success' rate. This is done by backpropagation. \n",
        "\n",
        "The value to which the weight must be adjust is calculated by partial differentation of the cost (How well the model is doing) to that particular weight/bias. This is done mainly via chain rule.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkYBWvU6ql9m"
      },
      "source": [
        "### Derivatives\n",
        "Manually calculating the derivatives results to the following:\n",
        "\n",
        "With respect to the output layer:\n",
        "$$\n",
        "\\begin{split}\n",
        "\\frac{\\partial C}{\\partial w_L} & = \\frac{\\partial C}{\\partial a_L} \\frac{\\partial a_L}{\\partial z_L} \\frac{\\partial z_L}{\\partial w_L} \\\\ \n",
        "& = (a_L - y) \\sigma'(z_L) a_{2}\n",
        "\\end{split}\n",
        "$$\n",
        "\\\\\n",
        "$$\n",
        "\\begin{split}\n",
        "\\frac{\\partial C}{\\partial b_L} & = \\frac{\\partial C}{\\partial a_L} \\frac{\\partial a_L}{\\partial z_L} \\\\\n",
        "& = (a_L - y) \\sigma'(z_L)\n",
        "\\end{split}\n",
        "$$\n",
        "To simplify, the partial derivative of the cost with respect to the $z$ can be defined as the error of that layer where:\n",
        "$$\n",
        "\\begin{split}\n",
        "Error_l & = \\frac{\\partial C}{\\partial z_l} \\\\\n",
        "Error_L & = \\frac{\\partial C}{\\partial a_L} \\frac{\\partial a_L}{\\partial z_L} \\\\\n",
        "& =  (a_L - y) \\sigma'(z_L)\n",
        "\\end{split}\n",
        "$$\n",
        "Then:\n",
        "$$\n",
        "\\begin{split}\n",
        "\\frac{\\partial C}{\\partial w_L} & = \\frac{\\partial C}{\\partial z_L} \\frac{\\partial z_L}{\\partial w_L} \\\\\n",
        "& = Error_L\\frac{\\partial z_L}{\\partial w_L}\\\\\n",
        "& = (a_L - y) \\sigma'(z_L) a_{2}\n",
        "\\end{split}\n",
        "$$\n",
        "\\\\\n",
        "$$\n",
        "\\begin{split}\n",
        "\\frac{\\partial C}{\\partial b_L} & = \\frac{\\partial C}{\\partial z_L} = Error_L \\\\\n",
        "& = (a_L - y) \\sigma'(z_L)\n",
        "\\end{split}\n",
        "$$\n",
        "\n",
        "Extending this to the weights and biases for the two hidden layers, $w_1, b_1$ and $w_2,b_2$:\n",
        "\n",
        "$$\n",
        "\\begin{split}\n",
        "\\frac{\\partial C}{\\partial w_2} & = \\frac{\\partial C}{\\partial z_L} \\frac{\\partial z_L}{\\partial a_2} \\frac{\\partial a_2}{\\partial z_2} \\frac{\\partial z_2}{\\partial w_2}\\\\\n",
        "& = Error_L\\frac{\\partial z_L}{\\partial a_2} \\frac{\\partial a_2}{\\partial z_2} \\frac{\\partial z_2}{\\partial w_2}\\\\\n",
        "& = Error_L \\cdot w_L \\cdot \\sigma'(z_2) \\cdot a_1 \\\\\n",
        "\\end{split}\n",
        "$$\n",
        "\\\\\n",
        "$$\n",
        "\\begin{split}\n",
        "\\frac{\\partial C}{\\partial b_2} & = \\frac{\\partial C}{\\partial z_L} \\\\\n",
        "& = Error_L \\cdot w_L \\cdot \\sigma'(z_2)\n",
        "\\end{split}\n",
        "$$\n",
        "Again, to simplify:\n",
        "$$\n",
        "\\begin{split}\n",
        "Error_2 & = Error_L\\frac{\\partial z_L}{\\partial a_2} \\frac{\\partial a_2}{\\partial z_2} \\\\\n",
        "& = Error_L \\cdot w_L \\cdot \\sigma'(z_2) \\\\\n",
        "\\end{split}\n",
        "$$\n",
        "\n",
        "Thus:\n",
        "$$\n",
        "\\frac{\\partial C}{\\partial w_2} = Error_2 \\cdot a_1\n",
        "$$\n",
        "\\\\\n",
        "$$\n",
        "\\begin{split}\n",
        "\\frac{\\partial C}{\\partial b_2} & = \\frac{\\partial C}{\\partial z_2} = Error_2 \\\\\n",
        "\\end{split}\n",
        "$$\n",
        "\n",
        "In general terms, it can be summarized that the partial derivative of the cost to any weight is just the error of that layer multiplied by the input. \n",
        "$$\n",
        "\\frac{\\partial C}{\\partial w_l} =  Error_l \\cdot Input_L\n",
        "$$\n",
        "and the partial derivative of the cost wrt any bias is just the layer error.\n",
        "$$\n",
        "\\frac{\\partial C}{\\partial b_l}  = \\frac{\\partial C}{\\partial z_l} = Error_l\n",
        "$$\n",
        "\n",
        "Then for the initial hidden layer, the partial derivatives are:\n",
        "$$\n",
        "Error_1 = Error_L \\cdot Error_2 \\cdot w_2 \\cdot \\sigma'(z_1)\n",
        "$$\n",
        "\\\\\n",
        "$$\n",
        "\\frac{\\partial C}{\\partial w_1} = Error_1 \\cdot x\n",
        "$$\n",
        "\\\\\n",
        "$$\n",
        "\\begin{split}\n",
        "\\frac{\\partial C}{\\partial b_1} & = \\frac{\\partial C}{\\partial z_1} = Error_1 \\\\\n",
        "\\end{split}\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCASnKp7SrOA"
      },
      "source": [
        "# Network Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seK3t1jg4ZZC"
      },
      "source": [
        "The neural network class will have 7 main methods to implement a simple NN.\n",
        "\n",
        "- forward_propagate\n",
        "- backward_propagate\n",
        "- compute_cost\n",
        "- compute_derivatives\n",
        "- update_parameters\n",
        "- fit\n",
        "- predict\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2c0cy1F5buF"
      },
      "source": [
        "Initially the parameters will have initial values. \n",
        "Weights and biases are initialized with values from the standard normal distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scRteFP7VvvP"
      },
      "source": [
        "class NeuralNetwork:\n",
        "  def __init__(self, architecture):\n",
        "    '''\n",
        "    Parameters:\n",
        "\n",
        "    architecture - array containing the number of neurons per layer.\n",
        "    '''\n",
        "\n",
        "    # Initialize the network architecture\n",
        "    self.L = architecture.size - 1 # L defines the last layer of the network.\n",
        "    self.n = architecture\n",
        "\n",
        "    # Create a dictionary to store the weights and biases\n",
        "    self.parameters = {}\n",
        "    \n",
        "    # Initialize network parameters\n",
        "    for i in range (1, self.L + 1): \n",
        "        # Initialize weights from the standard normal distribution\n",
        "        self.parameters[f'W{i}'] = np.random.randn(self.n[i], self.n[i - 1])\n",
        "        # Initialize rest of the parameters to 1\n",
        "        self.parameters[f'b{i}'] = np.ones((self.n[i], 1))\n",
        "        self.parameters[f'z{i}'] = np.ones((self.n[i], 1))\n",
        "        self.parameters[f'a{i}'] = np.ones((self.n[i], 1))\n",
        "    \n",
        "    # Initialize the first activated values a[0]\n",
        "    self.parameters['a0'] = np.ones((self.n[i], 1))\n",
        "    \n",
        "    # Initialize the cost:\n",
        "    self.parameters['C'] = 0\n",
        "    \n",
        "    # Create a dictionary for storing the derivatives:\n",
        "    self.derivatives = {}\n",
        "\n",
        "  def forward_propagate(self, X):\n",
        "    # Note that X here, is just one training example\n",
        "    self.parameters['a0'] = X\n",
        "    \n",
        "    # Calculate the activations for every hidden layer    \n",
        "    for l in range(1, self.L + 1):\n",
        "      self.parameters[f'z{l}'] = np.dot(self.parameters[f'W{l}'], self.parameters[f'a{l - 1}']) + self.parameters[f'b{l}']\n",
        "      if l == self.L:\n",
        "        self.parameters[f'a{l}'] = sigmoid(self.parameters[f'z{l}'])\n",
        "      else:\n",
        "        self.parameters[f'a{l}'] = relu(self.parameters[f'z{l}'])\n",
        "      \n",
        "  def compute_cost(self, y):\n",
        "    self.parameters['C'] = 0.5*(self.parameters[f'a{self.L}'] - y)**2\n",
        "  def compute_derivatives(self, y):\n",
        "    # Partial derivatives of the cost function with respect to z[L], W[L] and b[L]:        \n",
        "    # dzL\n",
        "    self.derivatives[f'dz{self.L}'] = (self.parameters[f'a{self.L}'] - y) * sigmoid_prime(self.parameters[f'z{self.L}'])\n",
        "    # dWL\n",
        "    self.derivatives[f'dW{self.L}'] = np.dot(self.derivatives[f'dz{self.L}'], np.transpose(self.parameters[f'a{self.L - 1}']))\n",
        "    # dbL\n",
        "    self.derivatives[f'db{self.L}'] = self.derivatives[f'dz{self.L}']\n",
        "    \n",
        "    # Partial derivatives (via manual code) of the cost function with respect to z[l], W[l] and b[l]\n",
        "    # self.derivatives[f'dz{2}'] = np.dot(np.transpose(self.parameters[f'W{self.L}']), self.derivatives[f'dz{self.L}'])*relu_prime(self.parameters[f'z1'])\n",
        "    # self.derivatives[f'dW{2}'] = np.dot(self.derivatives[f'dz{2}'], np.transpose(self.parameters[f'a1']))\n",
        "    # self.derivatives[f'db{2}'] = self.derivatives[f'dz{2}']\n",
        "\n",
        "    # self.derivatives[f'dz{1}'] = np.dot(np.transpose(self.parameters[f'W2']), self.derivatives[f'dz2'])*relu_prime(self.parameters[f'z1'])\n",
        "    # self.derivatives[f'dW{1}'] = np.dot(self.derivatives[f'dz1'], np.transpose(self.parameters[f'a0']))\n",
        "    # self.derivatives[f'db{1}'] = self.derivatives[f'dz{1}']\n",
        "\n",
        "    # Implementing the above in a loop using the pattern in the previous text:\n",
        "    for l in range(self.L-1, 0, -1):\n",
        "      self.derivatives[f'dz{l}'] = np.dot(np.transpose(self.parameters[f'W{l + 1}']), self.derivatives[f'dz{l + 1}'])*relu_prime(self.parameters[f'z{l}'])\n",
        "      self.derivatives[f'dW{l}'] = np.dot(self.derivatives[f'dz{l}'], np.transpose(self.parameters[f'a{l - 1}']))\n",
        "      self.derivatives[f'db{l}'] = self.derivatives[f'dz{l}']\n",
        "\n",
        "  def update_parameters(self, alpha):\n",
        "    for l in range(1, self.L+1):\n",
        "      self.parameters[f'W{l}'] -= alpha*self.derivatives[f'dW{l}']\n",
        "      self.parameters[f'b{l}'] -= alpha*self.derivatives[f'db{l}']\n",
        "    \n",
        "  def predict(self, x):\n",
        "    self.forward_propagate(x)\n",
        "    return self.parameters[f'a{self.L}']\n",
        "      \n",
        "  def fit(self, X, Y, num_iter, alpha = 0.1):\n",
        "    cost = []\n",
        "    for iter in range(0, num_iter):\n",
        "      c = 0 # Stores the cost\n",
        "      n_c = 0 # Stores the number of correct predictions\n",
        "      \n",
        "      for i in range(0, X.shape[0]):\n",
        "        x = X[i].reshape((X[i].size, 1))\n",
        "        y = Y[i]\n",
        "\n",
        "        self.forward_propagate(x)\n",
        "        self.compute_cost(y)\n",
        "        self.compute_derivatives(y)\n",
        "        self.update_parameters(alpha)\n",
        "        c += self.parameters['C']\n",
        "\n",
        "      # Average Cost over all samples per iteration\n",
        "      c = c/X.shape[0]\n",
        "      cost.append(c)\n",
        "      if (iter % 1 == 0):\n",
        "        print(f\"Iteration: {iter} Cost: {c}\")\n",
        "    return cost"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA1VGfEVJ6-U"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b93ulgVJ2gD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c24abf-fb0d-4d26-d76b-698c427cf8e0"
      },
      "source": [
        "# Defining the model architecture\n",
        "architecture = np.array([1, 64, 64, 1])\n",
        "\n",
        "# Creating the classifier\n",
        "classifier = NeuralNetwork(architecture)\n",
        "\n",
        "# #Training the classifier\n",
        "costs = classifier.fit(x_training, y_training, 20, alpha=0.1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "Iteration: 0 Cost: [[0.00193444]]\n",
            "Iteration: 1 Cost: [[0.00025961]]\n",
            "Iteration: 2 Cost: [[0.00025961]]\n",
            "Iteration: 3 Cost: [[0.00025961]]\n",
            "Iteration: 4 Cost: [[0.00025961]]\n",
            "Iteration: 5 Cost: [[0.00025961]]\n",
            "Iteration: 6 Cost: [[0.00025961]]\n",
            "Iteration: 7 Cost: [[0.00025961]]\n",
            "Iteration: 8 Cost: [[0.00025961]]\n",
            "Iteration: 9 Cost: [[0.00025961]]\n",
            "Iteration: 10 Cost: [[0.00025961]]\n",
            "Iteration: 11 Cost: [[0.00025961]]\n",
            "Iteration: 12 Cost: [[0.00025961]]\n",
            "Iteration: 13 Cost: [[0.00025961]]\n",
            "Iteration: 14 Cost: [[0.00025961]]\n",
            "Iteration: 15 Cost: [[0.00025961]]\n",
            "Iteration: 16 Cost: [[0.00025961]]\n",
            "Iteration: 17 Cost: [[0.00025961]]\n",
            "Iteration: 18 Cost: [[0.00025961]]\n",
            "Iteration: 19 Cost: [[0.00025961]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9axNiKwXVj8"
      },
      "source": [
        "# Cost Plot\n",
        "From 20 iterations, the cost decreases albeit in an abrupt way. From the second iteration it flattens and stays at a constant value. This is due to the derivatives being too small hence the difference is negligible and the overall cost does not change."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "xR7fS8d8WvYW",
        "outputId": "2cec61fb-c898-4c03-dc7a-e3c87339459e"
      },
      "source": [
        "x = np.linspace(0,20, num=20)\n",
        "y = np.array(costs).reshape((x.shape))\n",
        "plt.figure\n",
        "plt.plot(x,y)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3502237ac8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATpK849jWDn9"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs8c_qG2WBva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ef0bf1d-b9e7-4c8a-af9a-a59fcdf8e6ff"
      },
      "source": [
        "# Predicting the test set results:\n",
        "predictions = []\n",
        "for i in range(0, x_testing.shape[0]):\n",
        "  x = x_testing[i].reshape((x_testing[i].size, 1))\n",
        "  y = y_testing[i]\n",
        "  y_pred = classifier.predict(x)\n",
        "  predictions.append(y_pred)\n",
        "print(np.array(predictions).reshape(len(predictions),))\n",
        "print(y_testing.reshape((y_testing.shape[0],)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.42158145e-10 7.25811630e-12 1.80194100e-15 1.42827914e-12\n",
            " 3.59434253e-10 3.67767099e-11 2.41736157e-13 5.84839109e-17\n",
            " 9.70239375e-15 4.84295301e-14 2.65319353e-16]\n",
            "[0.0051 0.0079 0.0139 0.0095 0.0051 0.006  0.0103 0.0164 0.0123 0.0106\n",
            " 0.0158]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gJAaSMLZMkq"
      },
      "source": [
        "# Conclusion and Recommendation\n",
        "From the test results, the current model is shown to be not accurate. Changing the hyperparameters such as increasing the number of epochs and applying possible optimizations is suggested to improve the results."
      ]
    }
  ]
}